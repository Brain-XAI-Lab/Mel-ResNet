{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import os\n",
    "import noisereduce as nr\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "n_fft = 1024\n",
    "win_length = 1024\n",
    "hop_length = win_length // 4\n",
    "n_mel_channels = 80\n",
    "mel_fmin = 0.0\n",
    "mel_fmax = 8000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터 로드, 전처리 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    return y, sr\n",
    "\n",
    "def cut_audio_to_2_seconds(y, sr, duration=2):\n",
    "    num_samples = int(duration * sr)\n",
    "    if len(y) < num_samples:\n",
    "        # 2초보다 짧으면 데이터 끝에 무음 패딩 추가\n",
    "        padding = np.zeros(num_samples - len(y))\n",
    "        y_cut = np.concatenate((y, padding))\n",
    "    else: \n",
    "        y_cut = y[:num_samples]\n",
    "    return y_cut\n",
    "\n",
    "def resample_audio(y, orig_sr, target_sr=22050):\n",
    "    y_resampled = torchaudio.functional.resample(torch.tensor(y), orig_sr, target_sr)\n",
    "    return y_resampled.numpy()\n",
    "\n",
    "def reduce_noise(y, sr):\n",
    "    y_nr = nr.reduce_noise(y=y, sr=sr)\n",
    "    return y_nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mel 변환, 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mel_spect(data, sampling_rate):\n",
    "    mel_basis = librosa.filters.mel(sr=sampling_rate, n_fft=n_fft, n_mels=n_mel_channels, fmin=mel_fmin, fmax=mel_fmax).astype(np.float32)\n",
    "    hann_window = torch.hann_window(win_length, dtype=torch.float32)\n",
    "\n",
    "    p = (n_fft - hop_length) // 2\n",
    "    data = torch.from_numpy(data).float()\n",
    "    data = torch.nn.functional.pad(data, (p, p))\n",
    "    spec = torch.stft(data, n_fft, hop_length=hop_length, win_length=win_length, window=hann_window, center=False, return_complex=True)\n",
    "\n",
    "    magnitude = torch.abs(spec)\n",
    "    mel_basis = torch.from_numpy(mel_basis).float()\n",
    "    mel = torch.matmul(mel_basis, magnitude)\n",
    "    mel = torch.log(torch.clamp(mel, min=1e-5))\n",
    "\n",
    "    return mel.numpy()\n",
    "\n",
    "def save_mel_spect(mel_spect, save_path):\n",
    "    np.save(save_path, mel_spect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### mel 이미지로 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mel_spect(mel_spect, sr, hop_length, save_path=None):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    librosa.display.specshow(mel_spect, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-spectrogram')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wav 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path, save_path):\n",
    "    y, sr = load_data(file_path)\n",
    "    y_cut = cut_audio_to_2_seconds(y, sr)\n",
    "    y_resampled = resample_audio(y_cut, sr)\n",
    "    y_nr = reduce_noise(y_resampled, 22050)\n",
    "    mel_spect = convert_mel_spect(y_nr, 22050)\n",
    "    save_mel_spect(mel_spect, save_path)\n",
    "    return mel_spect  # Mel-spectrogram을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 전체 전처리, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save(base_path, save_path, save_img=False, sr=22050):\n",
    "    classes = os.listdir(base_path)\n",
    "    \n",
    "    for class_dir in classes:\n",
    "        class_path = os.path.join(base_path, class_dir)\n",
    "        save_class_path = os.path.join(save_path, class_dir)\n",
    "        os.makedirs(save_class_path, exist_ok=True)\n",
    "        \n",
    "        if os.path.isdir(class_path):\n",
    "            for filename in os.listdir(class_path):\n",
    "                if filename.endswith('.wav'):\n",
    "                    file_path = os.path.join(class_path, filename)\n",
    "                    try:\n",
    "                        mel_save_path = os.path.join(save_class_path, filename.replace('.wav', '.npy'))\n",
    "                        mel_spect = preprocess_audio(file_path, mel_save_path)\n",
    "                        save_mel_spect(mel_spect, mel_save_path)\n",
    "\n",
    "                        if save_img:\n",
    "                            plot_save_path = mel_save_path.replace('.npy', '.png')  # 이미지 파일 경로\n",
    "                            plot_mel_spect(mel_spect, sr, hop_length, plot_save_path) \n",
    "                             # 이미지로도 저장\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_base_path = 'G:/공유 드라이브/4N_PKNU/BXAI/BMI/Mel-ResNet/Voice/Augmented'\n",
    "preprocessed_save_path = \"C:/Users/yjcho/Desktop/mel-0709\"\n",
    "preprocess_and_save(augment_base_path, preprocessed_save_path, save_img=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
